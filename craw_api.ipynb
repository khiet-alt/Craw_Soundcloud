{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Members\n",
    "- Cao Thanh Khiết   19120544\n",
    "- Ninh Duy Huy      \n",
    "- Lê Minh Hữu\n",
    "- xxx\n",
    "- xxx\n",
    "# Task of each member\n",
    "- Cao Thanh Khiết\n",
    "    - Use SoundClound API to get data and write down them into csv file\n",
    "- Ninh Duy Huy\n",
    "    -\n",
    "- Lê Minh Hữu\n",
    "    - xxx\n",
    "- xxx\n",
    "    - xxx\n",
    "- xxx\n",
    "    - xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More information in README.md file\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = \"https://api-v2.soundcloud.com\"\n",
    "client_id = \"6gsNBd4mJwXr0LxTBh8VKBOrViK6Aj56\"\n",
    "client_id_query = \"?client_id={}\".format(client_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"top50_url.txt\" contains url of top lists ( system-playlists of top 50 tracks)\n",
    "# This cell Convert url_lists from txt file to List python\n",
    "url_entrypoint = \"url_entry/top50_url.txt\"\n",
    "# url_entrypoint = \"url_entry/top50_url_max.txt\"    # uncomment here to get more records, but it take much longer time (nearly 3 hours)\n",
    "sys_playlists_url = []\n",
    "\n",
    "with open(url_entrypoint) as file:\n",
    "    lines = [ sys_playlists_url.append(line.rstrip()) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending request for each system-playlists to get track_id of top system-playlists\n",
    "track_ids = []  # holding id of track\n",
    "\n",
    "for sys_url in sys_playlists_url:\n",
    "    try:\n",
    "        resolve_api = api + \"/resolve\" + client_id_query + \"&url={}\".format(sys_url)\n",
    "        res = requests.get(resolve_api)\n",
    "        for track in res.json()['tracks']:\n",
    "            track_ids.append(track['id'])\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From that track_id, we send request for each tracks to get user_id of each track\n",
    "user_ids = []   # containing id of user\n",
    "\n",
    "for track in track_ids:\n",
    "    try:\n",
    "        track_api = api + \"/tracks/{}\".format(track) + client_id_query\n",
    "        res = requests.get(track_api)\n",
    "        user_ids.append(res.json()['user']['id'])\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []  # containing detail information of each user\n",
    "\n",
    "for user_id in user_ids:\n",
    "    user_api = api + \"/users/{}\".format(user_id) + client_id_query\n",
    "    res = requests.get(user_api)\n",
    "    users.append(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a schema for User Dataframe and converting to CSV file\n",
    "users_table = pd.DataFrame({\n",
    "    'id': pd.Series([u['id'] if u['id'] else 'None' for u in [user for user in users]]),\n",
    "    'username': pd.Series([u['username'] if u['username'] else 'None' for u in [user for user in users]]),\n",
    "    'first_name': pd.Series([u['first_name'] if u['first_name'] else 'None' for u in [user for user in users]]),\n",
    "    'last_name': pd.Series([u['last_name'] if u['last_name'] else 'None' for u in [user for user in users]]),\n",
    "    'full_name': pd.Series([u['full_name'] if u['full_name'] else 'None' for u in [user for user in users]]),\n",
    "    'description': pd.Series([u['description'] if u['description'] else 'None' for u in [user for user in users]]),\n",
    "    'verified': pd.Series([u['verified'] if u['verified'] else 'None' for u in [user for user in users]]),\n",
    "    'city': pd.Series([u['city'] if u['city'] else 'None' for u in [user for user in users]]),\n",
    "    'country_code': pd.Series([u['country_code'] if u['country_code'] else 'None' for u in [user for user in users]]),\n",
    "    'followers_count': pd.Series([u['followers_count'] if u['followers_count'] else 'None' for u in [user for user in users]]),\n",
    "    'followings_count': pd.Series([u['followings_count'] if u['followings_count'] else 'None' for u in [user for user in users]]),\n",
    "    'comments_count': pd.Series([u['comments_count'] if u['comments_count'] else 'None' for u in [user for user in users]]),\n",
    "    'track_count': pd.Series([u['track_count'] if u['track_count'] else 'None' for u in [user for user in users]]),\n",
    "    'avatar_url': pd.Series([u['avatar_url'] if u['avatar_url'] else 'None' for u in [user for user in users]]),\n",
    "    'groups_count': pd.Series([u['groups_count'] if u['groups_count'] else 'None' for u in [user for user in users]]),\n",
    "    'playlist_count': pd.Series([u['playlist_count'] if u['playlist_count'] else 'None' for u in [user for user in users]]),\n",
    "    'reposts_count': pd.Series([u['reposts_count'] if u['reposts_count'] else 'None' for u in [user for user in users]]),\n",
    "    'last_modified': pd.Series([u['last_modified'] if u['last_modified'] else 'None' for u in [user for user in users]]),\n",
    "    'created_at': pd.Series([u['created_at'] if u['created_at'] else 'None' for u in [user for user in users]])\n",
    "})\n",
    "\n",
    "users_table.to_csv('Api_data/users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell parse playlist_id and track_id, writing it into playlists.csv file\n",
    "playlists = [] # Containing List of Dict, Dict includes playlist_id and track_ids property\n",
    "\n",
    "for user_id in user_ids:\n",
    "    user_api = api + \"/users/{}/playlists\".format(user_id) + client_id_query\n",
    "    try:\n",
    "        res = requests.get(user_api)\n",
    "        collection = res.json()['collection']\n",
    "        # loop\n",
    "        for playlist in collection:\n",
    "            playlist_id = playlist['id']\n",
    "            track_id_string = ''\n",
    "            for item in playlist['tracks']:\n",
    "                track_id_string += str(item['id']) + ','\n",
    "            track_id_string = track_id_string[:-1] if track_id_string != '' else 'None'\n",
    "            playlists.append({\n",
    "                'playlist_id': playlist_id,\n",
    "                'track_ids': track_id_string\n",
    "            })\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "playlists_table = pd.DataFrame(playlists)\n",
    "playlists_table.to_csv('Api_data/playlists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information of each track from playlists.csv file\n",
    "tracks_detail = []\n",
    "read_playlists = pd.read_csv('Api_data/playlists.csv')\n",
    "# parse string from playlists.csv file to get track_id and send request to retrive detail information of each track\n",
    "\n",
    "for index, row in read_playlists.iterrows():\n",
    "    tracks = row['track_ids'].split(',')\n",
    "    for track in tracks:\n",
    "        \n",
    "        if track == 'None':\n",
    "            continue\n",
    "        track_api = api + \"/tracks/{}\".format(track) + client_id_query\n",
    "        res = requests.get(track_api)\n",
    "        tracks_detail.append(res.json())\n",
    "\n",
    "# Remove some unnessesary property of each track\n",
    "key_remover = ['artwork_url', 'publisher_metadata', 'media', 'user', 'badges']\n",
    "\n",
    "for key in key_remover:\n",
    "    for dic in tracks_detail:\n",
    "        dic.pop(key, None)\n",
    "\n",
    "# convert infor track into csv file\n",
    "track_df = pd.DataFrame(tracks_detail)\n",
    "track_df.to_csv('Api_data/tracks.csv')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "628dd01b888ab9cdfddc3a0771c5db8a998a3af968dbb11740c2370c8ddf1b03"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('min_ds-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
