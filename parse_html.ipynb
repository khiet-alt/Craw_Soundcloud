{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd9e96c",
   "metadata": {},
   "source": [
    "- Nguyễn Tuấn Khoa 19120547\n",
    "    - parse HTML\n",
    "- Ninh Duy Huy 19120533\n",
    "    - parse HTML\n",
    "- Lê Minh Hữu 19120525\n",
    "    - parse HTML\n",
    "- Trần Tuấn Kiệt 19120xxx\n",
    "    - parse HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0798153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DELL\\\\miniconda3\\\\envs\\\\min_ds-env\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed1a2491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests_cache\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import pandas as pd # Dùng để đọc và hiển thị file csv/tsv\n",
    "from datetime import datetime, timedelta # Dùng để xử lý dữ liệu thời gian\n",
    "import os\n",
    "import urllib.robotparser # Kiểm tra file robot.txt có được phép crawl không"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef71bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllUrls(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        urls = []\n",
    "        while f.tell() != os.fstat(f.fileno()).st_size:\n",
    "            url = f.readline()\n",
    "            if url != '':\n",
    "                url = url.replace('\\n','')\n",
    "                urls.extend(url)\n",
    "    f.close()\n",
    "    return urls\n",
    "\n",
    "def GetUsers(soup):\n",
    "    Users = []\n",
    "    TagUsers = soup.findAll('a', {})\n",
    "    return Users\n",
    "def GetTracks(soup):\n",
    "    return True\n",
    "def GetPlaylist(soup):\n",
    "    return True\n",
    "def ParseTop50(urls):\n",
    "    info = []\n",
    "    for url in urls:\n",
    "        r = request.get(url)\n",
    "        soup = BeautifulSoup(r.content.decode('utf-8'), 'html.parser')\n",
    "        \n",
    "        time.sleep(1)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd72a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './url_entry/top50_url.txt'\n",
    "urls = GetAllUrls(filename)\n",
    "info = ParseTop50(urls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
